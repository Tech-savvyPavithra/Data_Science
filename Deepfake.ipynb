{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tech-savvyPavithra/Data_Science/blob/main/Deepfake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR4MPmJnpmD-",
        "outputId": "7ceac6ba-2738-4a41-a6d2-c05c35ac1079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4y5VtZL3hBQ",
        "outputId": "32c03b20-7bd5-4cfd-ef3e-f0466b87b4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/AliaksandrSiarohin/first-order-model\n",
            "  Cloning https://github.com/AliaksandrSiarohin/first-order-model to /tmp/pip-req-build-jz4hy_s4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AliaksandrSiarohin/first-order-model /tmp/pip-req-build-jz4hy_s4\n",
            "  Resolved https://github.com/AliaksandrSiarohin/first-order-model to commit f4ff6da1ef5c0e6bcf6ec80324fab37c92193e84\n",
            "\u001b[31mERROR: git+https://github.com/AliaksandrSiarohin/first-order-model does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (67.7.2)\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'model_params'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cd24b56441b0>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Perform image animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriving_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-cd24b56441b0>\u001b[0m in \u001b[0;36mload_checkpoints\u001b[0;34m(config_path, checkpoint_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n\u001b[0m\u001b[1;32m     39\u001b[0m                                         **config['model_params']['common_params'])\n\u001b[1;32m     40\u001b[0m     kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_params'"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install git+https://github.com/AliaksandrSiarohin/first-order-model\n",
        "!pip install imageio imageio-ffmpeg\n",
        "\n",
        "# Import necessary libraries\n",
        "import imageio.v2 as imageio\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import torch\n",
        "import requests\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# Define paths\n",
        "source_image_path = \"/content/drive/MyDrive/Colab Notebooks/My Workouts/test2.jpg\"\n",
        "driving_video_path = \"/content/drive/MyDrive/Colab Notebooks/My Workouts/dance.mp4\"\n",
        "output_path = \"/content/drive/MyDrive/Colab Notebooks/My Workouts/save.mp4\"\n",
        "config_path = \"/content/vox-256.yaml\"\n",
        "checkpoint_path = \"/content/vox-cpk.pth.tar\"\n",
        "\n",
        "# Pull config file from GitHub\n",
        "config_url = \"https://raw.githubusercontent.com/AliaksandrSiarohin/first-order-model/main/config/vox-256.yaml\"\n",
        "if not os.path.exists(config_path):\n",
        "    with open(config_path, 'wb') as f:\n",
        "        f.write(requests.get(config_url).content)\n",
        "\n",
        "# Pull checkpoint file from GitHub\n",
        "checkpoint_url = \"https://github.com/AliaksandrSiarohin/first-order-model/raw/main/vox-cpk.pth.tar\"\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    with open(checkpoint_path, 'wb') as f:\n",
        "        f.write(requests.get(checkpoint_url).content)\n",
        "\n",
        "# Load checkpoints\n",
        "def load_checkpoints(config_path, checkpoint_path):\n",
        "    from demo import OcclusionAwareGenerator, KPDetector\n",
        "    with open(config_path) as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
        "                                        **config['model_params']['common_params'])\n",
        "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
        "                             **config['model_params']['common_params'])\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    generator.load_state_dict(checkpoint['generator'])\n",
        "    kp_detector.load_state_dict(checkpoint['kp_detector'])\n",
        "    generator.to('cuda').eval()\n",
        "    kp_detector.to('cuda').eval()\n",
        "    return generator, kp_detector\n",
        "\n",
        "# Load source image\n",
        "source_image = imageio.imread(source_image_path)\n",
        "source_image = resize(source_image, (256, 256))[..., :3]\n",
        "source_image = torch.tensor(source_image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2).to('cuda')\n",
        "\n",
        "# Load driving video\n",
        "reader = imageio.get_reader(driving_video_path)\n",
        "driving_video = []\n",
        "for frame in reader:\n",
        "    frame = resize(frame, (256, 256))[..., :3]\n",
        "    driving_video.append(frame)\n",
        "driving_video = np.array(driving_video)\n",
        "driving_video = torch.tensor(driving_video.astype(np.float32)).permute(0, 3, 1, 2).to('cuda')\n",
        "\n",
        "# Perform image animation\n",
        "generator, kp_detector = load_checkpoints(config_path, checkpoint_path)\n",
        "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
        "\n",
        "# Save animation\n",
        "imageio.mimsave(output_path, [img_as_ubyte(frame) for frame in predictions])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPixOon84NApzEFfxxqWRSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}